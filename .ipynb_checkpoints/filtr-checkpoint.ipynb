{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "import os\n",
    "import time\n",
    "import helper_pol as h\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "\n",
    "load_dotenv()\n",
    "#load_dotenv('/home/ca-polandsys/.env')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_code = 'PL'\n",
    "\n",
    "h.connect_to_rdb()\n",
    "query = r\"SELECT min(max_report_date) AS max_report_date FROM stats.vw_partner_consumer_data_loads_by_country WHERE country_code = '\"+country_code+\"' AND fact_table IN ('spotify.fact_streams','spotify.fact_streams_orchard')\"\n",
    "spotify_max_date_df = h.query_sql(query)\n",
    "\n",
    "spotify_max_date = datetime.today()\n",
    "\n",
    "try:\n",
    "    spotify_max_date = spotify_max_date_df['max_report_date'].loc[0]\n",
    "\n",
    "except:\n",
    "    next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"sql/tracks_sme.sql\", \"r\") as file:\n",
    "    tracks_sme_sql = file.read()\n",
    "    \n",
    "    \n",
    "tracks_sme_sql = tracks_sme_sql.replace('2024-01-07',spotify_max_date.strftime(\"%Y-%m-%d\"))\n",
    "tracks_sme_sql = tracks_sme_sql.replace('_COUNTRY_CODE_',country_code)\n",
    "tracks_sme_df = h.query_sql(tracks_sme_sql)\n",
    "tracks_sme_df['feed'] = 'SME'\n",
    "\n",
    "\n",
    "with open(\"sql/tracks_orchard.sql\", \"r\") as file:\n",
    "    tracks_orch_sql = file.read()\n",
    "\n",
    "tracks_orch_sql = tracks_orch_sql.replace('2024-01-07',spotify_max_date.strftime(\"%Y-%m-%d\"))\n",
    "tracks_orch_sql = tracks_orch_sql.replace('_COUNTRY_CODE_',country_code)\n",
    "tracks_orch_df = h.query_sql(tracks_orch_sql)\n",
    "tracks_orch_df['feed'] = 'ORCHARD'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracks_df = pd.concat([tracks_sme_df, tracks_orch_df], ignore_index=True)\n",
    "\n",
    "df_metadata = tracks_df.drop_duplicates(subset='track_isrc')\n",
    "df_metadata = df_metadata.drop(columns=['segment_name','segment_streams'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_isrcs = ','.join([\"'{}'\".format(isrc) for isrc in df_metadata['track_isrc']])\n",
    "\n",
    "with open(\"sql/metadane_release_date.sql\", \"r\") as file:\n",
    "    metadane_release_date_sql = file.read()\n",
    "\n",
    "metadane_release_date_sql = metadane_release_date_sql.replace('_ISRC_CD_',combined_isrcs)\n",
    "metadane_release_date = h.query_sql(metadane_release_date_sql)\n",
    "metadane_release_date['release_date'] = pd.to_datetime(metadane_release_date['release_date'])\n",
    "\n",
    "min_release_dates_df = metadane_release_date.groupby('track_isrc')['release_date'].min().reset_index()\n",
    "min_release_dates_df = pd.DataFrame(min_release_dates_df, columns=['track_isrc', 'release_date'])\n",
    "\n",
    "df_metadata = pd.merge(df_metadata, min_release_dates_df, on='track_isrc', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot_df = pd.pivot_table(tracks_df, values='segment_streams', index=['track_isrc'],\n",
    "                          columns='segment_name', aggfunc='sum', fill_value=0)\n",
    "genres_df = pivot_df.div(pivot_df.sum(axis=1), axis=0) * 100\n",
    "genres_df.reset_index(inplace=True)\n",
    "\n",
    "none_df = (tracks_df.groupby('track_isrc')\n",
    "                       .apply(lambda x: x.loc[x['segment_name'].isna(), 'segment_streams'].sum() / x['segment_streams'].sum())\n",
    "                       .reset_index(name='share_of_none_values'))\n",
    "\n",
    "genres_df = pd.merge(genres_df, none_df, on='track_isrc', how='outer')\n",
    "\n",
    "\n",
    "genres_df = pd.merge(df_metadata, genres_df, on='track_isrc', how='inner')\n",
    "genres_df = genres_df.sort_values(by='total_streams', ascending=False)\n",
    "genres_df.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#Top Hity – Top150 SME+O, ALL\n",
    "\n",
    "playlist_id = '7Le3oCnCpgDO0etNcbyTeM'\n",
    "h.refresh_spotify_conn()\n",
    "\n",
    "df_playlist = genres_df[0:150]\n",
    "\n",
    "if len(df_playlist) >= 0:\n",
    "    h.spotify_remove_all_tracks_from_playlist(playlist_id)\n",
    "    h.spotify_update_playlist_description(playlist_id,'Dane na dzien '+spotify_max_date.strftime(\"%Y-%m-%d\"))\n",
    "    group_size = 100\n",
    "    track_uri_groups = [df_playlist['_track_uri'].iloc[i:i+group_size].to_list() for i in range(0, len(df_playlist), group_size)]\n",
    "\n",
    "    for i in range(len(track_uri_groups)-1, -1, -1):\n",
    "        track_uri = track_uri_groups[i]\n",
    "        h.spotify_add_tracks(playlist_id,track_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Top Hity – Top150 SME+O, ALL\n",
    "\n",
    "playlist_id = '7Le3oCnCpgDO0etNcbyTeM'\n",
    "h.refresh_spotify_conn()\n",
    "\n",
    "df_playlist = genres_df[0:150]\n",
    "\n",
    "if len(df_playlist) >= 0:\n",
    "    h.spotify_remove_all_tracks_from_playlist(playlist_id)\n",
    "    h.spotify_update_playlist_description(playlist_id,'Dane na dzien '+spotify_max_date.strftime(\"%Y-%m-%d\"))\n",
    "    group_size = 100\n",
    "    track_uri_groups = [df_playlist['_track_uri'].iloc[i:i+group_size].to_list() for i in range(0, len(df_playlist), group_size)]\n",
    "\n",
    "    for i in range(len(track_uri_groups)-1, -1, -1):\n",
    "        track_uri = track_uri_groups[i]\n",
    "        h.spotify_add_tracks(playlist_id,track_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All tracks removed from the playlist.\n",
      "All tracks removed from the playlist.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Rap hity – Top150 SME+O, ALL\n",
    "\n",
    "playlist_id = '5QqmWfetEZ7IfMvyJycezG'\n",
    "h.refresh_spotify_conn()\n",
    "\n",
    "df_playlist = genres_df[(genres_df['rap']>75.0) | genres_df['_track_uri'].str.contains('rap|hip-hop', case=False, regex=True)][0:150]\n",
    "\n",
    "if len(df_playlist) >= 0:\n",
    "    h.spotify_remove_all_tracks_from_playlist(playlist_id)\n",
    "    h.spotify_update_playlist_description(playlist_id,'Dane na dzien '+spotify_max_date.strftime(\"%Y-%m-%d\"))\n",
    "    group_size = 100\n",
    "    track_uri_groups = [df_playlist['_track_uri'].iloc[i:i+group_size].to_list() for i in range(0, len(df_playlist), group_size)]\n",
    "\n",
    "    for i in range(len(track_uri_groups)-1, -1, -1):\n",
    "        track_uri = track_uri_groups[i]\n",
    "        h.spotify_add_tracks(playlist_id,track_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All tracks removed from the playlist.\n",
      "All tracks removed from the playlist.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Gram w grę – Top150 SME+O, ALL\n",
    "\n",
    "playlist_id = '4HIyk5bEmoPJVaXwhN3oJu'\n",
    "h.refresh_spotify_conn()\n",
    "\n",
    "df_playlist = genres_df[(genres_df['edm']>25.0) | ((genres_df['rap']>55.0) & (genres_df['edm']>1.0)) | genres_df['_track_uri'].str.contains('rap|hip-hop|electro|edm', case=False, regex=True)][0:150]\n",
    "\n",
    "if len(df_playlist) >= 0:\n",
    "    h.spotify_remove_all_tracks_from_playlist(playlist_id)\n",
    "    h.spotify_update_playlist_description(playlist_id,'Dane na dzien '+spotify_max_date.strftime(\"%Y-%m-%d\"))\n",
    "    group_size = 100\n",
    "    track_uri_groups = [df_playlist['_track_uri'].iloc[i:i+group_size].to_list() for i in range(0, len(df_playlist), group_size)]\n",
    "\n",
    "    for i in range(len(track_uri_groups)-1, -1, -1):\n",
    "        track_uri = track_uri_groups[i]\n",
    "        h.spotify_add_tracks(playlist_id,track_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#PPP – Top150 SME+O, ALL\n",
    "\n",
    "playlist_id = '0Tt1VCYMzvK0KtKySr18So'\n",
    "h.refresh_spotify_conn()\n",
    "\n",
    "df_playlist = genres_df[(genres_df['edm']>30.0) | (genres_df['_track_uri'].str.contains('electro|edm', case=False, regex=True))][0:150]\n",
    "\n",
    "if len(df_playlist) >= 0:\n",
    "    h.spotify_remove_all_tracks_from_playlist(playlist_id)\n",
    "    h.spotify_update_playlist_description(playlist_id,'Dane na dzien '+spotify_max_date.strftime(\"%Y-%m-%d\"))\n",
    "    group_size = 100\n",
    "    track_uri_groups = [df_playlist['_track_uri'].iloc[i:i+group_size].to_list() for i in range(0, len(df_playlist), group_size)]\n",
    "\n",
    "    for i in range(len(track_uri_groups)-1, -1, -1):\n",
    "        track_uri = track_uri_groups[i]\n",
    "        h.spotify_add_tracks(playlist_id,track_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All tracks removed from the playlist.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Top Hity – Top150 SME+O, ALL\n",
    "\n",
    "playlist_id = '5wGiR9VtUNlfSGaqa7Wniw'\n",
    "h.refresh_spotify_conn()\n",
    "\n",
    "cutoff_date = datetime.now() - timedelta(days=56)\n",
    "df_playlist = genres_df[genres_df['release_date'] <= cutoff_date][0:150]\n",
    "\n",
    "if len(df_playlist) >= 0:\n",
    "    h.spotify_remove_all_tracks_from_playlist(playlist_id)\n",
    "    h.spotify_update_playlist_description(playlist_id,'Dane na dzien '+spotify_max_date.strftime(\"%Y-%m-%d\"))\n",
    "    group_size = 100\n",
    "    track_uri_groups = [df_playlist['_track_uri'].iloc[i:i+group_size].to_list() for i in range(0, len(df_playlist), group_size)]\n",
    "\n",
    "    for i in range(len(track_uri_groups)-1, -1, -1):\n",
    "        track_uri = track_uri_groups[i]\n",
    "        h.spotify_add_tracks(playlist_id,track_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
